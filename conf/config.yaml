---
defaults:
  - _self_
  - /run_mode: dev
  - /model: LabelProp
name: dev  # set experiment name
name_tag: null  # if specified, the final name becomes ${name}-${name_tag}
group: main
seed: 0
num_runs: 1
num_workers: 0  # 0 uses all available threads
log_level: INFO
save_results: false  # enable CSVLogger to save results
paths:
  homedir: .
  runtime_dir: ${paths.homedir}/runtime
  result_dir: ${paths.homedir}/results/${group}
  dataset_dir: ${paths.homedir}/datasets
  gene_list_path: ${paths.homedir}/genes.txt
dataset:
  network: ???
  label: ???
  node_encoders: LapEigMap
wandb:
  use: true
  name: null  # use wandb autogenerated name if set to null
  group: ${group}
  entity: RemyLiu
  project: OBNB-dev
metric:
  options:
    - APOP
    - AP
    - AUROC
  best: APOP
  obj: max
trainer:
  accelerator: auto
  devices: 1
  inference_only: false  # turn on for LabelProp
  max_epochs: 50_000
  eval_interval: 20
  early_stopping_patience: 500
  gradient_clip_val: 0.02  # set to null to disable
  fast_dev_run: false
  watch_grad_norm: true
model:
  name: unknown
  hid_dim: 128
  mp_type: GINConv
  mp_layers: 5
  mp_kwargs: null
  residual_type: skipsum
  dropout: 0.2
  norm_type: DiffGroupNorm
  norm_kwargs: null
  act: relu
  act_first: false
  pred_head_layers: 1
  skip_pred_act: false
  use_edge_feature: true
  post_prop:
    enable: false
    num_layers: 10
    alpha: 0.9  # the "not restart" (the converse of teleporting) probability
    norm: left
    dropout: 0.0
    cached: true
  post_cands:
    enable: false
    num_correction_layers: 100
    num_smoothing_layers: 100
    correction_alpha: 1.0
    smoothing_alpha: 0.8
    correction_norm: sym
    smoothing_norm: left
    autoscale: false
    scale: 1.0
    cached: true
optim:
  lr: 0.01
  weight_decay: 1e-6
  optimizer: AdamW
  optimizer_kwargs: null
  scheduler: ReduceLROnPlateau
  scheduler_kwargs:
    mode: ${metric.obj}
    patience: 100
    min_lr: 1e-5
    factor: 0.5
node_encoder_params:
  OneHotLogDeg:
    raw_dim: 32
    enc_dim: 128
    raw_bn: true
    raw_dropout: 0.0
    dropout: 0.2
    layers: 1
  Constant:
    raw_dim: 1
    enc_dim: 128
    raw_bn: false
    raw_dropout: 0.0
    dropout: 0.2
    layers: 1
  RandomNormal:
    raw_dim: 32
    enc_dim: 128
    raw_bn: true
    raw_dropout: 0.0
    dropout: 0.2
    layers: 1
  Orbital:
    enc_dim: 128
    raw_bn: true
    raw_dropout: 0.0
    dropout: 0.2
    layers: 1
    feat_kwargs:
      graphlet_size: 3
  SVD:
    raw_dim: 128
    enc_dim: 128
    raw_bn: true
    raw_dropout: 0.5
    dropout: 0.2
    layers: 1
  LapEigMap:
    raw_dim: 128
    enc_dim: 128
    raw_bn: true
    raw_dropout: 0.0
    dropout: 0.2
    layers: 1
  RandomWalkDiag:
    raw_dim: 128
    enc_dim: 128
    raw_bn: true
    raw_dropout: 0.0
    dropout: 0.2
    layers: 1
  RandProjGaussian:
    raw_dim: 128
    enc_dim: 128
    raw_bn: true
    raw_dropout: 0.2
    dropout: 0.2
    layers: 1
  RandProjSparse:
    raw_dim: 128
    enc_dim: 128
    raw_bn: true
    raw_dropout: 0.2
    dropout: 0.2
    layers: 1
  LINE1:
    raw_dim: 128
    enc_dim: 128
    raw_bn: true
    raw_dropout: 0.5
    dropout: 0.2
    layers: 1
  LINE2:
    raw_dim: 128
    enc_dim: 128
    raw_bn: true
    raw_dropout: 0.5
    dropout: 0.2
    layers: 1
  Node2vec:
    raw_dim: 128
    enc_dim: 128
    raw_bn: true
    raw_dropout: 0.5
    dropout: 0.2
    layers: 1
    feat_kwargs:
      num_walks: 10
      walk_length: 40
      window_size: 5
      p: 1.0  # return parameter for node2vec
      q: 1.0  # in-out parameter for node2vec
      mode: PreCompFirstOrder  # PecanPy mode
      extend: false  # true for node2vec+ doi.org/10.1093/bioinformatics/btad047
      gamma: 0.0  # node2vec+ thresholding parameter
      epochs: 5  # default Gensim Word2vec setting
  Walklets:
    raw_dim: 128
    enc_dim: 128
    raw_bn: true
    raw_dropout: 0.5
    dropout: 0.2
    layers: 1
    feat_kwargs:
      walk_length: 50
      iterations: 10
      window_size: 3  # up to third order neighborhoods
      epochs: 5  # default Gensim Word2vec setting
  Adj:
    enc_dim: 128
    raw_bn: true
    raw_dropout: 0.5
    dropout: 0.2
    layers: 1
  AdjEmbBag:
    raw_dim: 128
    enc_dim: 128
    raw_bn: false
    raw_dropout: 0.2
    dropout: 0.2
    layers: 0
  Embedding:
    raw_dim: 128
    enc_dim: 128
    raw_bn: false
    raw_dropout: 0.2
    dropout: 0.2
    layers: 0
  LabelReuse:  # turn off dropout and remove enc for LabelProp
    raw_bn: true
    enc_dim: 128
    raw_dropout: 0.5
    dropout: 0.2
    layers: 1
  Composed:
    enc_dim: 128
    raw_bn: false
    raw_dropout: 0.0
    dropout: 0.2
    layers: 2
hydra:
  run:
    dir: ${paths.runtime_dir}/hydra/${now:%Y-%m-%d}/${now:%H-%M-%S}
